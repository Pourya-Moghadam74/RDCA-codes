{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cd6133",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d82a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyclustering.cluster.clique import clique\n",
    "from pyclustering.cluster.clique import clique_visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f25408",
   "metadata": {},
   "source": [
    "### Implementing CLIQUE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = ?\n",
    "# Density threshold\n",
    "threshold = ?\n",
    "number_of_features = ?\n",
    "clique_instance = clique(np.array(df.iloc[:,:number_of_features]), intervals, threshold)\n",
    "# clique_instance = clique(data_M, intervals, threshold)\n",
    "# Start the clustering process and get the results\n",
    "clique_instance.process()\n",
    "clique_cluster = clique_instance.get_clusters()  # allocated clusters\n",
    "\n",
    "# Points considered as outliers (noise points)\n",
    "noise = clique_instance.get_noise()\n",
    "# CLIQUE formed grid unit\n",
    "cells = clique_instance.get_cells() \n",
    "num_of_clusters = len(clique_cluster)\n",
    "print(\"Amount of clusters:\", num_of_clusters)\n",
    "print(clique_cluster)\n",
    "\n",
    "#determining the label of each data point based on CLIQUE cluster\n",
    "num_of_clusters = len(clique_cluster)\n",
    "data_cluster = {}\n",
    "for i in range(num_of_clusters):\n",
    "    for item in clique_cluster[i]:\n",
    "        data_cluster[item] = i\n",
    "        \n",
    "#identifying cells which is related to a cluster        \n",
    "cell_cluster = {}\n",
    "for j in range(len(cells)):\n",
    "    try:\n",
    "        cell_cluster[cells[j]] = data_cluster.get(cells[j].points[0])\n",
    "    except:\n",
    "        cell_cluster[cells[j]] = -1\n",
    "        \n",
    "        \n",
    "for i in range(len(df)):\n",
    "    if i not in data_cluster.keys():\n",
    "        data_cluster[i] = -1\n",
    "        \n",
    "labelsss = []\n",
    "for item in sorted(data_cluster.items(), key=lambda x: x[0]):\n",
    "    labelsss.append(item[1])\n",
    "    \n",
    "df[\"Cluster\"] = labelsss\n",
    "label_list = set(labelsss) - {-1}\n",
    "label_list = sorted(label_list)\n",
    "max_cell = np.zeros((num_of_clusters,number_of_features))\n",
    "min_cell = np.zeros((num_of_clusters,number_of_features))\n",
    "\n",
    "for item in label_list:\n",
    "    temp = df[df[\"Cluster\"] == item].iloc[:,:number_of_features]\n",
    "    min_cell[item,:] = np.array(np.min(temp, axis=0))\n",
    "    max_cell[item,:] = np.array(np.max(temp, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddc087",
   "metadata": {},
   "source": [
    "### Defining major fucntions for RDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340de3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_back_cell(item):\n",
    "    for elm in cells:\n",
    "        if str(elm) == str(item):\n",
    "            return elm.spatial_location.get_corners()\n",
    "        \n",
    "#==========================================================================================================================    \n",
    "\n",
    "def cell_location(index_of_cluster):\n",
    "    filterd_dict = {}\n",
    "    filterd_dict = {k:v for (k,v) in cell_cluster.items() if v == index_of_cluster}\n",
    "    return (filterd_dict, len(filterd_dict))\n",
    "\n",
    "#==========================================================================================================================    \n",
    "\n",
    "def RDA_initial_population(index_of_cluster,kind):\n",
    "    \n",
    "    global num_of_population\n",
    "    num_of_population = 40\n",
    "    initial_population = []\n",
    "    \n",
    "    if kind == \"my_method\":\n",
    "        initial_population = np.random.uniform(min_cell[index_of_cluster,:], max_cell[index_of_cluster,:], size=(num_of_population, number_of_features)).tolist()\n",
    "        return initial_population\n",
    "    \n",
    "    elif kind == \"normal\":\n",
    "        temp = []\n",
    "        for iterr in range(num_of_population):\n",
    "            for i in range(number_of_features):\n",
    "                temp.append(np.random.uniform(min_borders[i], max_borders[i]))\n",
    "            initial_population.append(temp)\n",
    "            temp = []\n",
    "        return initial_population \n",
    "    \n",
    "#==========================================================================================================================    \n",
    "                   \n",
    "def compatness_measure(point):\n",
    "    global within_cluster_result\n",
    "    within_cluster_result = {}\n",
    "\n",
    "    for item in point:\n",
    "        matrix = np.zeros((len(df), num_of_clusters))\n",
    "        for i in range(len(point[item])):\n",
    "            matrix[:,i] = np.linalg.norm(np.broadcast_to(point[item][i], (len(df),number_of_features)) - np.array(df.iloc[:,:number_of_features]), axis=1).tolist()\n",
    "    \n",
    "        matrix = np.concatenate((matrix.min(axis=1).reshape(len(df),1),np.argmin(matrix,axis=1).reshape(len(df),1)), axis=1)\n",
    "        within_cluster_result[item] = np.mean(npi.group_by(matrix[:, 1]).mean(matrix[:,0])[1])  \n",
    "        \n",
    "    return within_cluster_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def get_labels(point):\n",
    "    global labels\n",
    "    labels = {}\n",
    "    \n",
    "    for item in point:\n",
    "        matrix2 = np.ones((len(df), num_of_clusters))*np.inf\n",
    "        for i in range(len(point[item])):\n",
    "            matrix2[:,i] = np.linalg.norm(np.broadcast_to(point[item][i], (len(df),number_of_features)) - np.array(df.iloc[:,:number_of_features]), axis=1).tolist()\n",
    "        labels[item] = np.argmin(matrix2,axis=1)\n",
    "    return labels\n",
    "    \n",
    "#==========================================================================================================================    \n",
    "\n",
    "def seperation_measure(point):\n",
    "    global between_cluster_distance\n",
    "    between_cluster_distance = {}\n",
    "    tmp = 0\n",
    "    for item in point:\n",
    "        if len(point[item]) != 1:\n",
    "            for i in range(len(point[item])):\n",
    "                for j in range(i+1,len(point[item])):\n",
    "                    tmp += (np.linalg.norm(np.array(point[item][i])-np.array(point[item][j])))\n",
    "            between_cluster_distance[item] = tmp/(comb(len(point[item]), 2))\n",
    "            tmp = 0\n",
    "        else:\n",
    "            between_cluster_distance[item] = np.linalg.norm(np.array(point[item][0]))\n",
    "    return between_cluster_distance\n",
    "\n",
    "#==========================================================================================================================    \n",
    "\n",
    "def combined_measure(point):\n",
    "    global w1,w2\n",
    "    compactness_result = compatness_measure(point)\n",
    "    separation_result = seperation_measure(point)\n",
    "    \n",
    "    combined_result = {}\n",
    "    for i in point:\n",
    "        flag = 0\n",
    "        for k in range(len(point[i])):\n",
    "            for j in range(len(point[i][k])):\n",
    "                if point[i][k][j] > max_borders[j] or point[i][k][j] < min_borders[j]:\n",
    "                    flag = 1\n",
    "                    break\n",
    "        if flag == 1:\n",
    "            combined_result[i] = 10**10\n",
    "        else:\n",
    "            combined_result[i] = (w1*compactness_result[i]) - (w2*separation_result[i])\n",
    "    return combined_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "turi_random_value = np.random.normal(2,1)\n",
    "def turi_index_measure(point):\n",
    "    global min_value_turi,turi_measure_result\n",
    "    turi_measure_result = {}\n",
    "    intra = compatness_measure(point)\n",
    "    c = 1\n",
    "    turi_index_value = []\n",
    "    min_value_turi = np.inf\n",
    "    for item in point:\n",
    "        if len(point[item]) != 1:\n",
    "            for i in range(len(point[item])):\n",
    "                for j in range(i+1,len(point[item])):\n",
    "                    min_value_turi = min((np.linalg.norm(np.array(point[item][i])-np.array(point[item][j]))), min_value_turi)\n",
    "                    turi_measure_result[item] = intra[item]/min_value_turi\n",
    "        else:\n",
    "            min_value_turi = np.linalg.norm(np.array(point[item][0]))\n",
    "            turi_measure_result[item] = intra[item]/min_value_turi\n",
    "        \n",
    "    return turi_measure_result\n",
    "\n",
    "#==========================================================================================================================    \n",
    "\n",
    "def S_Dbw_measure(point):\n",
    "    s_dbw_measure_result = {}\n",
    "    label = get_labels(point)\n",
    "    \n",
    "    for item in point:\n",
    "        if len(set(get_labels({0: point[item]})[0])) >= 2:\n",
    "            s_dbw_measure_result[item] = S_Dbw(np.array(df.iloc[:, :number_of_features]),label[item] , centers_id=None, method='Tong', alg_noise='bind',\n",
    "        centr='mean', nearest_centr=True, metric='euclidean')\n",
    "        else:\n",
    "            s_dbw_measure_result[item] = 10**5\n",
    "    return s_dbw_measure_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def dunn_index_measure(point):\n",
    "    point_index = list(point.keys())[0]\n",
    "    label = get_labels(point)[point_index]\n",
    "    temp = list(set(label))\n",
    "     \n",
    "    data_points = [[] for number in range(len(temp))]\n",
    "    for i in range(len(label)):\n",
    "        data_points[label[i]].append(i)\n",
    "\n",
    "    min_value_dunn = np.inf\n",
    "    max_value_dunn = -np.inf\n",
    "    for i in range(len(data_points)):\n",
    "        for j in range(len(data_points[i])):\n",
    "            for m in range(j+1, len(data_points[i])):\n",
    "                max_value_dunn = max(max_value_dunn,(np.linalg.norm(np.array(df.iloc[data_points[i][j],:number_of_features]) - np.array(df.iloc[data_points[i][m], :number_of_features]))))\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(data_points)):\n",
    "        for j in range(i+1, len(data_points)):\n",
    "            for m in data_points[i]:\n",
    "                for n in data_points[j]:\n",
    "                    min_value_dunn = min(min_value_dunn,(np.linalg.norm(np.array(df.iloc[m,:number_of_features]) - np.array(df.iloc[n, :number_of_features]))))\n",
    "\n",
    "    min_value_dunn = min_value_dunn / max_value_dunn\n",
    "    return min_value_dunn\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def db_measure(point):\n",
    "    global db_measure_result\n",
    "    db_measure_result = {}\n",
    "    for item in point:\n",
    "        if len(set(get_labels({0: point[item]})[0])) >= 2:\n",
    "            db_measure_result[item] = davies_bouldin_score(df.iloc[:, :number_of_features], get_labels({0: point[item]})[0])\n",
    "        else:\n",
    "            db_measure_result[item] = 10**5\n",
    "    return db_measure_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def silhouette_measure(point):\n",
    "    global silhouette_measure_result\n",
    "    silhouette_measure_result = {}\n",
    "    for item in point:\n",
    "        if len(set(get_labels({0: point[item]})[0])) >= 2:\n",
    "            silhouette_measure_result[item] = silhouette_score(df.iloc[:, :number_of_features], get_labels({0: point[item]})[0])\n",
    "        else:\n",
    "            silhouette_measure_result[item] = -10**5\n",
    "    return silhouette_measure_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def ARI_measure(point):\n",
    "    ari_measure_result = {}\n",
    "    label = get_labels(point)\n",
    "    \n",
    "    for item in point:\n",
    "        if len(set(get_labels({0: point[item]})[0])) >= 2:\n",
    "            ari_measure_result[item] = adjusted_rand_score(df['class'], label[0])\n",
    "        else:\n",
    "            ari_measure_result[item] = 10**5\n",
    "    return ari_measure_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def nmi_measure(point):\n",
    "    nmi_measure_result = {}\n",
    "    label = get_labels(point)\n",
    "    \n",
    "    for item in point:\n",
    "        if len(set(get_labels({0: point[item]})[0])) >= 2:\n",
    "            nmi_measure_result[item] = normalized_mutual_info_score(df['class'], label[0])\n",
    "        else:\n",
    "            nmi_measure_result[item] = 10**5\n",
    "    return nmi_measure_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def custom_function(point):\n",
    "    global custom_function_result\n",
    "    custom_function_result = {}\n",
    "    \n",
    "    for item in point:\n",
    "        custom_function_result[item] = (np.sum(np.array(point[item])**2))\n",
    "    return custom_function_result\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def fitness_function (point, measure):\n",
    "    if measure == 'compactness':\n",
    "        return compatness_measure(point)\n",
    "    elif measure == 'separation':\n",
    "        return seperation_measure(point)\n",
    "    elif measure == 'combined':\n",
    "        return combined_measure(point)\n",
    "    elif measure == 'turi':\n",
    "        return turi_index_measure(point)\n",
    "    elif measure == 'db':\n",
    "        return db_measure(point)\n",
    "    elif measure == 'nmi':\n",
    "        return nmi_measure(point)\n",
    "    elif measure == 'silhouette':\n",
    "        return silhouette_measure(point)\n",
    "    elif measure == 'custom':\n",
    "        return custom_function(point)\n",
    "#==========================================================================================================================\n",
    "\n",
    "def generate_candidates():\n",
    "    global candidates, random_candidates\n",
    "    candidates = {}\n",
    "    can_index = 0\n",
    "    number_of_samples = 150\n",
    "    random_candidates = np.random.randint(0,num_of_population,(int(number_of_samples*1.25),num_of_clusters))\n",
    "    random_candidates = np.unique(random_candidates, axis=0)\n",
    "    for item in random_candidates:\n",
    "        can_element = []\n",
    "        c = 0\n",
    "        for item2 in item:\n",
    "            can_element.append(population[c][item2])\n",
    "            c += 1\n",
    "        candidates[can_index] = can_element\n",
    "        can_index += 1\n",
    "    return candidates\n",
    "\n",
    "#==========================================================================================================================    \n",
    "\n",
    "def RDA_select_Nmale():\n",
    "    global Nmales, Nhinds\n",
    "    Nmales = {}\n",
    "    Nhinds = {}\n",
    "    alpha = 0.15\n",
    "    num_of_Nmale = np.round(alpha*(len(random_candidates)), 0)\n",
    "#     num_of_Nmale = 15\n",
    "    i = 0\n",
    "    if optimize_method == 'min':\n",
    "        sorted_fitness_measure = sorted(fitness_result.items(), key= lambda x: x[1])\n",
    "    elif optimize_method == 'max':\n",
    "        sorted_fitness_measure = sorted(fitness_result.items(), key= lambda x: x[1], reverse=True)\n",
    "    for item in sorted_fitness_measure :\n",
    "        if i < num_of_Nmale:\n",
    "            Nmales[item[0]] = candidates[item[0]]\n",
    "            i += 1\n",
    "        else:\n",
    "            Nhinds[item[0]] = candidates[item[0]]\n",
    "\n",
    "#==========================================================================================================================    \n",
    "\n",
    "min_borders = []\n",
    "max_borders = []\n",
    "for num in range(number_of_features):\n",
    "    min_borders.append(min(df.iloc[:, num]))\n",
    "    max_borders.append(max(df.iloc[:, num]))\n",
    "    \n",
    "def RDA_find_ub_lb():\n",
    "    global UB, LB\n",
    "    UB = np.broadcast_to(1*max_borders, (num_of_clusters, number_of_features))\n",
    "    LB = np.broadcast_to(1*min_borders, (num_of_clusters, number_of_features))\n",
    "    \n",
    "#==========================================================================================================================\n",
    "\n",
    "def RDA_roaring(kind):\n",
    "    global new\n",
    "    for item in Nmales:\n",
    "        new = []\n",
    "        a3 = np.random.uniform()\n",
    "        a2 = np.random.uniform()\n",
    "        a1 = np.random.uniform()\n",
    "        if a3 >= 0.5:\n",
    "            new = (Nmales[item] + a1*(((UB - LB)*a2) +LB)).tolist()\n",
    "        else:\n",
    "            new = (Nmales[item] - a1*(((UB - LB)*a2) +LB)).tolist()\n",
    "        \n",
    "        \n",
    "        if kind == 'my_method':\n",
    "            find_mean({6666: Nmales[item]})\n",
    "            a = fitness_function({0: new}, measure)[0]\n",
    "            b = fitness_result[item]\n",
    "            c = fitness_function({0: mean[6666]}, measure)[0]\n",
    "\n",
    "            if optimize_method == 'min':\n",
    "                temp_result = np.argmin([a, b, c])\n",
    "            elif optimize_method == 'max':\n",
    "                temp_result = np.argmax([a, b, c])\n",
    "                \n",
    "        elif kind == 'normal':\n",
    "            a = fitness_function({0: new}, measure)[0]\n",
    "            b = fitness_result[item]\n",
    "\n",
    "            if optimize_method == 'min':\n",
    "                temp_result = np.argmin([a, b])\n",
    "            elif optimize_method == 'max':\n",
    "                temp_result = np.argmax([a, b])\n",
    "                \n",
    "                \n",
    "        if temp_result == 0:\n",
    "            Nmales[item] = new\n",
    "            candidates[item] = new\n",
    "            fitness_result[item] = a\n",
    "      \n",
    "        elif temp_result == 2:\n",
    "            Nmales[item] = mean[6666]\n",
    "            candidates[item] = mean[6666]\n",
    "            fitness_result[item] = c\n",
    "#==========================================================================================================================\n",
    "\n",
    "def RDA_select_commanders():\n",
    "    global commanders, stags,after_roaring_result\n",
    "    commanders = {}\n",
    "    stags = {}\n",
    "    gamma = 0.7\n",
    "    num_of_commanders = np.round(gamma*len(Nmales), 0)\n",
    "    i = 0\n",
    "    after_roaring_result = fitness_function(Nmales, measure)\n",
    "    \n",
    "    if optimize_method == 'min':\n",
    "        sorted_Nmales = sorted(after_roaring_result.items(), key= lambda x: x[1])\n",
    "    elif optimize_method == 'max':\n",
    "        sorted_Nmales = sorted(after_roaring_result.items(), key= lambda x: x[1], reverse=True)\n",
    "        \n",
    "    for item in sorted_Nmales:\n",
    "        if i < num_of_commanders:\n",
    "            commanders[item[0]] = Nmales[item[0]]\n",
    "            i += 1\n",
    "        else:\n",
    "            stags[item[0]] = Nmales[item[0]]     \n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def find_mean(point):\n",
    "    #point should be in dictionary format\n",
    "    global mean\n",
    "    mean = {}\n",
    "    point_index = list(point.keys())[0]\n",
    "    label = get_labels(point)[point_index]\n",
    "    mean_matrix = np.concatenate((np.array(df.iloc[:, :number_of_features]),label.reshape(len(df),-1)),axis=1)\n",
    "    mean[6666] = npi.group_by(mean_matrix[:, -1]).mean(mean_matrix[:,:-1])[1].tolist()\n",
    "    if len(mean[6666]) != num_of_clusters:\n",
    "        label_list = set(label)\n",
    "        temp_point = point[6666]\n",
    "        counter = 0\n",
    "        for label in label_list:\n",
    "            temp_point[label] = mean[6666][counter]\n",
    "            counter += 1\n",
    "        mean[6666] = temp_point\n",
    "#==========================================================================================================================\n",
    "\n",
    "def RDA_fight(comm,kind):\n",
    "    for item in comm:\n",
    "        b1 = np.random.uniform()\n",
    "        b2 = np.random.uniform()\n",
    "        \n",
    "        stag_index = list(stags.keys())[np.random.randint(len(stags))]\n",
    "        mianeh = np.array(commanders[item]) + np.array(stags[stag_index])\n",
    "        new1 = ((mianeh/2) + b1 * (((UB - LB)*b2) + LB)).tolist()\n",
    "        new2 = ((mianeh/2) - b1 *(((UB - LB)*b2) + LB)).tolist()\n",
    "        \n",
    "        if kind == \"my_method\":\n",
    "            find_mean({6666: comm[item]})\n",
    "            a = fitness_function({0: new1},measure)[0]\n",
    "            b = fitness_function({0: new2},measure)[0]\n",
    "            c = fitness_result[item]\n",
    "            d = fitness_result[stag_index]\n",
    "            e = fitness_function({0: mean[6666]}, measure)[0]\n",
    "            if optimize_method == 'min':\n",
    "                temp_result1 = np.argmin([a, b, c, d, e])\n",
    "            elif optimize_method == 'max':\n",
    "                temp_result1 = np.argmax([a, b, c, d, e])\n",
    "                \n",
    "        elif kind == \"normal\":\n",
    "            a = fitness_function({0: new1},measure)[0]\n",
    "            b = fitness_function({0: new2},measure)[0]\n",
    "            c = fitness_result[item]\n",
    "            d = fitness_result[stag_index]\n",
    "            if optimize_method == 'min':\n",
    "                temp_result1 = np.argmin([a, b, c, d])\n",
    "            elif optimize_method == 'max':\n",
    "                temp_result1 = np.argmax([a, b, c, d])\n",
    "\n",
    "        if temp_result1 == 0:\n",
    "            commanders[item] = new1\n",
    "            Nmales[item] = new1\n",
    "            candidates[item] = new1\n",
    "            fitness_result[item] = a\n",
    "        elif temp_result1 == 1:\n",
    "            commanders[item] = new2\n",
    "            Nmales[item] = new2\n",
    "            candidates[item] = new2\n",
    "            fitness_result[item] = b\n",
    "        elif temp_result1 == 3:\n",
    "            tt = commanders[item] \n",
    "            commanders[item] = stags[stag_index]\n",
    "            stags[stag_index] = tt\n",
    "            comm_re = fitness_result[item]\n",
    "            stag_re = fitness_result[stag_index]\n",
    "            fitness_result[item] = stag_re\n",
    "            fitness_result[stag_index] = comm_re\n",
    "            \n",
    "#==========================================================================================================================\n",
    "        \n",
    "def RDA_form_harems(comm):\n",
    "    global Nharem, num_of_harem_members\n",
    "    Nharem = {}\n",
    "    num_of_harem_members = {}\n",
    "\n",
    "    \n",
    "    sum_of_vi = 0\n",
    "    \n",
    "    if optimize_method == 'min':\n",
    "        maximum_vi = -np.inf\n",
    "        for item in comm:\n",
    "            maximum_vi = max(fitness_result[item], maximum_vi)\n",
    "            \n",
    "    elif optimize_method == 'max':\n",
    "        maximum_vi = np.inf\n",
    "        for item in comm:\n",
    "            maximum_vi = min(fitness_result[item], maximum_vi)\n",
    "            \n",
    "    for item in comm:\n",
    "        sum_of_vi += (fitness_result[item] - maximum_vi)\n",
    "        \n",
    "    Nhinds_index = list(Nhinds.keys())    \n",
    "    for item in comm:\n",
    "        temp = []\n",
    "        if sum_of_vi == 0:\n",
    "            num_of_harem_members[item] = int(len(Nhinds)/len(comm))\n",
    "        else:\n",
    "            num_of_harem_members[item] = int(np.round(np.abs(((fitness_result[item] - maximum_vi)/sum_of_vi)*len(Nhinds)), 0))\n",
    "        for i in range(min(num_of_harem_members[item], len(Nhinds_index))):\n",
    "            random_index = np.random.randint(len(Nhinds_index))\n",
    "            temp.append(Nhinds[Nhinds_index[random_index]])\n",
    "            Nhinds_index.remove(Nhinds_index[random_index])\n",
    "        Nharem[item] = temp\n",
    "        \n",
    "#==========================================================================================================================        \n",
    "        \n",
    "def RDA_comm_mate_with_its_harem(nharem):\n",
    "    \n",
    "    global offspring\n",
    "    alpha = 0.9\n",
    "    offspring = {}\n",
    "    offspring_index = len(candidates)\n",
    "    \n",
    "    for item in nharem:\n",
    "        num_of_mate = alpha * len(Nharem[item])\n",
    "        \n",
    "        if Nharem[item] != []:\n",
    "            Nharem_index = list(range(len(Nharem[item])))\n",
    "            \n",
    "            for i in range(int(num_of_mate)):\n",
    "                Nharem_random_index = random.choice(Nharem_index)\n",
    "                c = np.random.uniform()\n",
    "                \n",
    "                mianeh = (np.array(commanders[item]) + np.array(Nharem[item][Nharem_random_index])/2)\n",
    "                temp = (mianeh + ((UB - LB) * c)).tolist()\n",
    "                \n",
    "                Nharem_index.remove(Nharem_random_index)\n",
    "                offspring[offspring_index] = temp\n",
    "                offspring_index += 1\n",
    "\n",
    "#==========================================================================================================================        \n",
    "        \n",
    "def RDA_comm_mate_with_other_harem(comm):\n",
    "    global selected_harem, Nharem_index\n",
    "    beta = 0.4\n",
    "    offspring_index = len(offspring) + len(candidates)\n",
    "    for item in comm:\n",
    "        harem_list = list(Nharem.keys())\n",
    "        harem_list.remove(item)\n",
    "        count = 0\n",
    "        while True:\n",
    "\n",
    "            selected_harem = random.choice(harem_list)\n",
    "            count += 1\n",
    "            if Nharem[selected_harem] != [] or count == 10:\n",
    "                break\n",
    "\n",
    "        num_of_mate = int(beta * len(Nharem[selected_harem]))\n",
    "\n",
    "        Nharem_index = list(range(len(Nharem[selected_harem])))\n",
    "        for i in range(num_of_mate):\n",
    "            Nharem_random_index = random.choice(Nharem_index)\n",
    "            c = np.random.uniform()\n",
    "            mianeh = (np.array(commanders[item]) + np.array(Nharem[selected_harem][Nharem_random_index])/2)\n",
    "            temp = (mianeh + ((UB -LB) * c)).tolist()\n",
    "\n",
    "            Nharem_index.remove(Nharem_random_index)\n",
    "            offspring[offspring_index] = temp\n",
    "            offspring_index += 1\n",
    "                \n",
    "# #==========================================================================================================================\n",
    "\n",
    "    \n",
    "def RDA_stag_mate_with_nearest_hind(stagss):\n",
    "    offspring_index = len(offspring) + len(candidates)\n",
    "    global stag_hind_mate\n",
    "    stag_hind_mate = {}\n",
    "    for item in stagss:\n",
    "        temp = []\n",
    "        for hind in Nhinds:\n",
    "            temp.append(np.linalg.norm(np.array(stags[item]) - np.array(Nhinds[hind])))\n",
    "        stag_hind_mate[item] = list(Nhinds.keys())[temp.index(min(temp))]\n",
    "    \n",
    "    for item in stag_hind_mate:\n",
    "        c = np.random.uniform()\n",
    "        mianeh = (np.array(stags[item]) + np.array(Nhinds[stag_hind_mate[item]])/2)\n",
    "        temp2 = (mianeh + ((UB - LB) * c)).tolist()\n",
    "\n",
    "        offspring[offspring_index] = temp2\n",
    "        offspring_index += 1\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "def RDA_next_generation():\n",
    "    global all_result, next_generation_index, next_generation_Nhinds, next_generation_Nmales, new_candidates, Nmales, candidates, Nhinds, fitness_result\n",
    "    all_result = {}\n",
    "    next_generation_index = 0\n",
    "    lists = [fitness_result, fitness_offs_result]\n",
    "    for item in lists:\n",
    "        for item2 in item:\n",
    "            all_result[item2] = item[item2]\n",
    "            \n",
    "    if optimize_method == 'min':\n",
    "        sorted_all_result = sorted(all_result.items(), key= lambda x: x[1])\n",
    "    elif optimize_method == 'max':\n",
    "        sorted_all_result = sorted(all_result.items(), key= lambda x: x[1], reverse=True)\n",
    "        \n",
    "    new_candidates = {}\n",
    "    next_generation_Nmales = {}\n",
    "    temp_hinds = {}\n",
    "    i = 0\n",
    "\n",
    "    for elemnt in sorted_all_result:\n",
    "        if i < len(Nmales):\n",
    "            try:\n",
    "                next_generation_Nmales[next_generation_index] = candidates[elemnt[0]]\n",
    "            except:\n",
    "                next_generation_Nmales[next_generation_index] = offspring[elemnt[0]]\n",
    "            next_generation_index += 1   \n",
    "            i += 1\n",
    "        else:\n",
    "            temp_hinds[elemnt[0]] = all_result[elemnt[0]]\n",
    "    \n",
    "    if optimize_method == 'min':\n",
    "        max_value = max(temp_hinds.values())\n",
    "    elif optimize_method == 'max':\n",
    "        max_value = min(temp_hinds.values())\n",
    "        \n",
    "    new_values = {}\n",
    "    p_values = []\n",
    "    next_generation_Nhinds = {}\n",
    "    \n",
    "    if optimize_method == 'min':\n",
    "        if max_value >= 0:\n",
    "            for item in temp_hinds:\n",
    "                new_values[item] = max_value + (max_value - temp_hinds[item])\n",
    "\n",
    "        else:\n",
    "            for item in temp_hinds:\n",
    "                new_values[item] = -temp_hinds[item]\n",
    "                \n",
    "    elif optimize_method == 'max':\n",
    "        if max_value <= 0:\n",
    "            for item in temp_hinds:\n",
    "                new_values[item] = max_value + (max_value - temp_hinds[item])\n",
    "\n",
    "        else:\n",
    "            for item in temp_hinds:\n",
    "                new_values[item] = temp_hinds[item]\n",
    "                \n",
    "    sum_values = sum(new_values.values())\n",
    "    for item in new_values:\n",
    "        p_values.append(new_values[item]/sum_values)\n",
    "\n",
    "    for i in range(len(Nhinds)):\n",
    "        index = np.random.choice(list(temp_hinds.keys()), p=p_values)\n",
    "        try:\n",
    "            next_generation_Nhinds[next_generation_index] = candidates[index]\n",
    "        except:\n",
    "            next_generation_Nhinds[next_generation_index] = offspring[index]\n",
    "        next_generation_index += 1\n",
    "\n",
    "    lists2 = [next_generation_Nmales, next_generation_Nhinds]\n",
    "    new_candidates = {}\n",
    "    fitness_result = {}\n",
    "    for item in lists2:\n",
    "        for item2 in item:\n",
    "            new_candidates[item2] = item[item2]\n",
    "            fitness_result[item2] = fitness_function({0: item[item2]}, measure)[0]\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ec159",
   "metadata": {},
   "source": [
    "### RDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56acfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = ?\n",
    "num_of_clusters = ?\n",
    "\n",
    "new_rda_compactness = []\n",
    "new_rda_separation = []\n",
    "new_rda_combined = []\n",
    "new_rda_turi = []\n",
    "new_rda_dunn = []\n",
    "new_rda_db = []\n",
    "new_rda_nmi = []\n",
    "new_rda_best = []\n",
    "new_rda_time = []\n",
    "pop = []\n",
    "w1,w2 = 0.95,0.05\n",
    "measure = 'combined'\n",
    "optimize_method = 'min'\n",
    "for iterr in np.arange(30):\n",
    "    start = time.time()\n",
    "    population = {}\n",
    "    for i in range(num_of_clusters):\n",
    "        population[i] = RDA_initial_population(i, 'my_method')\n",
    "\n",
    "    candidates = generate_candidates()\n",
    "    fitness_result = fitness_function(candidates,measure)\n",
    "    RDA_select_Nmale()\n",
    "    RDA_find_ub_lb()\n",
    "    temp_result = []\n",
    "    temp_new_rda_compactness = []\n",
    "    temp_new_rda_separation = []\n",
    "    temp_new_rda_combined = []\n",
    "    temp_new_rda_turi = []\n",
    "    temp_new_rda_dunn = []\n",
    "    temp_new_rda_db = []\n",
    "    temp_new_rda_nmi = []\n",
    "    temp_new_rda_best = []\n",
    "    temp_pop = []\n",
    "    for iteration in range(80):\n",
    "        RDA_roaring('my_method')\n",
    "        RDA_select_commanders()\n",
    "        RDA_fight(commanders,\"my_method\")\n",
    "        RDA_form_harems(commanders)\n",
    "        RDA_comm_mate_with_its_harem(Nharem)\n",
    "        RDA_comm_mate_with_other_harem(commanders)\n",
    "        RDA_stag_mate_with_nearest_hind(stags)\n",
    "        fitness_offs_result = fitness_function(offspring, measure)\n",
    "        RDA_next_generation()\n",
    "        Nmales = next_generation_Nmales\n",
    "        Nhinds = next_generation_Nhinds\n",
    "        candidates = new_candidates\n",
    "        alll = sorted(fitness_result.items(), key=lambda x:x[1])\n",
    "        commander_index = alll[0][0]\n",
    "        temp_new_rda_compactness.append(fitness_function({0: candidates[commander_index]},'compactness')[0])\n",
    "        temp_new_rda_separation.append(fitness_function({0: candidates[commander_index]},'separation')[0])\n",
    "        temp_new_rda_combined.append(fitness_function({0: candidates[commander_index]},'combined')[0])\n",
    "        temp_new_rda_turi.append(fitness_function({0: candidates[commander_index]},'turi')[0])\n",
    "        temp_new_rda_db.append(fitness_function({0: candidates[commander_index]},'db')[0])\n",
    "        temp_new_rda_nmi.append(fitness_function({0: candidates[commander_index]},'nmi')[0])\n",
    "        temp_new_rda_best.append(candidates[commander_index])\n",
    "        temp_pop.append(candidates)\n",
    "        \n",
    "    end = time.time()\n",
    "    new_rda_time.append(end - start)\n",
    "    new_rda_compactness.append(temp_new_rda_compactness)\n",
    "    new_rda_separation.append(temp_new_rda_separation)\n",
    "    new_rda_combined.append(temp_new_rda_combined)\n",
    "    new_rda_turi.append(temp_new_rda_turi)\n",
    "    new_rda_db.append(temp_new_rda_db)\n",
    "    new_rda_nmi.append(temp_new_rda_nmi)\n",
    "    new_rda_best.append(temp_new_rda_best)\n",
    "    pop.append(temp_pop)\n",
    "    print(\"We completed the %ith iteration\" %(iterr+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
